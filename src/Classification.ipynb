{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer(as_frame=True)\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=500, max_depth=5, random_state=42),\n",
    "    'DecisionStump': DecisionTreeClassifier(max_depth=1, random_state=42),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = []\n",
    "roc_curve_data = []\n",
    "conf_matrices = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]  \n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary',  zero_division=0)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    roc_curve_data.append({\n",
    "        'FPR': fpr,\n",
    "        'TPR': tpr,\n",
    "        'ROC AUC': auc,\n",
    "        'Model': name\n",
    "    })\n",
    "      \n",
    "    summary.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'ROC AUC': auc,\n",
    "    })\n",
    "\n",
    "    conf_matrices[name] = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = pd.DataFrame(summary)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"                        ðŸ“Š MODELLVERGLEICH ERGEBNISSE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_display = df_summary.copy()\n",
    "numeric_columns = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']\n",
    "df_display[numeric_columns] = df_display[numeric_columns].round(4)\n",
    "\n",
    "print(df_display.to_string(index=False, \n",
    "                          float_format='%.4f',\n",
    "                          col_space=12,\n",
    "                          justify='center'))\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharex=True, sharey=True)\n",
    "\n",
    "for ax, (name, cm) in zip(axes, conf_matrices.items()):\n",
    "    im = ax.imshow(cm, cmap='Blues', aspect='auto')\n",
    "    ax.set_title(f\"{name} - Confusion Matrix\")\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_xticklabels(['bÃ¶sartig', 'gutartig'], rotation=45, ha='right')\n",
    "    ax.set_yticklabels(['bÃ¶sartig', 'gutartig'])\n",
    "    for (i, j), val in np.ndenumerate(cm):\n",
    "        color = 'white' if val > cm.max() / 2 else 'black'\n",
    "        ax.text(j, i, val, ha='center', va='center', color=color)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig2, axes2 = plt.subplots(1, 2, figsize=(12, 5), sharex=True, sharey=True)\n",
    "\n",
    "for ax, metric in zip(axes2, roc_curve_data):\n",
    "    fpr = metric['FPR']\n",
    "    tpr = metric['TPR']\n",
    "    auc = metric['ROC AUC']\n",
    "    name = metric['Model']\n",
    "\n",
    "    ax.plot(fpr, tpr, label=f'AUC = {auc:.2f}')\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_title(f\"{name} - ROC Curve\")\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
